import keras
from keras.models import Model
from keras import layers
import keras.backend as K
import numpy as np
from keras.layers.core import Lambda
import tensorflow as tf


weights_dict = dict()
def load_weights_from_file(weight_file):
    try:
        weights_dict = np.load(weight_file).item()
    except:
        weights_dict = np.load(weight_file, encoding='bytes').item()

    return weights_dict


def set_layer_weights(model, weights_dict):
    for layer in model.layers:
        if layer.name in weights_dict:
            cur_dict = weights_dict[layer.name]
            current_layer_parameters = list()
            if layer.__class__.__name__ == "BatchNormalization":
                if 'scale' in cur_dict:
                    current_layer_parameters.append(cur_dict['scale'])
                if 'bias' in cur_dict:
                    current_layer_parameters.append(cur_dict['bias'])
                current_layer_parameters.extend([cur_dict['mean'], cur_dict['var']])
            elif layer.__class__.__name__ == "Scale":
                if 'scale' in cur_dict:
                    current_layer_parameters.append(cur_dict['scale'])
                if 'bias' in cur_dict:
                    current_layer_parameters.append(cur_dict['bias'])
            elif layer.__class__.__name__ == "SeparableConv2D":
                current_layer_parameters = [cur_dict['depthwise_filter'], cur_dict['pointwise_filter']]
                if 'bias' in cur_dict:
                    current_layer_parameters.append(cur_dict['bias'])
            elif layer.__class__.__name__ == "Embedding":
                current_layer_parameters.append(cur_dict['weights'])
            else:
                # rot weights
                current_layer_parameters = [cur_dict['weights']]
                if 'bias' in cur_dict:
                    current_layer_parameters.append(cur_dict['bias'])
            model.get_layer(layer.name).set_weights(current_layer_parameters)

    return model


def KitModel(weight_file = None):
    global weights_dict
    weights_dict = load_weights_from_file(weight_file) if not weight_file == None else None
        
    transpose = layers.Input(shape=(224, 224, 3))
    init_Pad        = layers.ZeroPadding2D(name='init/Pad', padding=((3, 3), (3, 3)))(transpose)
    init_init_conv_conv2d_Conv2D = convolution(weights_dict, name='init/init_conv/conv2d/Conv2D', input=init_Pad, group=1, conv_type='layers.Conv2D', filters=64, kernel_size=(7, 7), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=None)
    stages_0_block_0_conv1_b1_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_0_block_0/conv1_b1_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(init_init_conv_conv2d_Conv2D)
    stages_0_block_0_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_0_block_0/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(init_init_conv_conv2d_Conv2D)
    stages_0_block_0_Relu = layers.Activation(name='stages_0_block_0/Relu', activation='relu')(stages_0_block_0_conv1_b1_bn_batch_normalization_FusedBatchNorm)
    stages_0_block_0_Relu_1 = layers.Activation(name='stages_0_block_0/Relu_1', activation='relu')(stages_0_block_0_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_0_block_0_Pad = layers.ZeroPadding2D(name='stages_0_block_0/Pad', padding=((0, 0), (0, 0)))(stages_0_block_0_Relu)
    stages_0_block_0_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_0_block_0/conv1_b2/conv2d/Conv2D', input=stages_0_block_0_Relu_1, group=1, conv_type='layers.Conv2D', filters=64, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_0_block_0_conv1_b1_conv2d_Conv2D = convolution(weights_dict, name='stages_0_block_0/conv1_b1/conv2d/Conv2D', input=stages_0_block_0_Pad, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=None)
    stages_0_block_0_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_0_block_0/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_0_block_0_conv1_b2_conv2d_Conv2D)
    stages_0_block_0_Relu_2 = layers.Activation(name='stages_0_block_0/Relu_2', activation='relu')(stages_0_block_0_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_0_block_0_Pad_1 = layers.ZeroPadding2D(name='stages_0_block_0/Pad_1', padding=((1, 1), (1, 1)))(stages_0_block_0_Relu_2)
    stages_0_block_0_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_0_block_0/conv2_b2/conv2d/Conv2D', input=stages_0_block_0_Pad_1, group=1, conv_type='layers.Conv2D', filters=64, kernel_size=(3, 3), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=None)
    stages_0_block_0_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_0_block_0/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_0_block_0_conv2_b2_conv2d_Conv2D)
    stages_0_block_0_Relu_3 = layers.Activation(name='stages_0_block_0/Relu_3', activation='relu')(stages_0_block_0_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_0_block_0_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_0_block_0/conv3_b2/conv2d/Conv2D', input=stages_0_block_0_Relu_3, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_0_block_0_add = my_add()([stages_0_block_0_conv3_b2_conv2d_Conv2D, stages_0_block_0_conv1_b1_conv2d_Conv2D])
    stages_0_block_1_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_0_block_1/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_0_block_0_add)
    stages_0_block_1_Relu = layers.Activation(name='stages_0_block_1/Relu', activation='relu')(stages_0_block_1_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_0_block_1_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_0_block_1/conv1_b2/conv2d/Conv2D', input=stages_0_block_1_Relu, group=1, conv_type='layers.Conv2D', filters=64, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_0_block_1_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_0_block_1/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_0_block_1_conv1_b2_conv2d_Conv2D)
    stages_0_block_1_Relu_1 = layers.Activation(name='stages_0_block_1/Relu_1', activation='relu')(stages_0_block_1_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_0_block_1_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_0_block_1/conv2_b2/conv2d/Conv2D', input=stages_0_block_1_Relu_1, group=1, conv_type='layers.Conv2D', filters=64, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_0_block_1_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_0_block_1/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_0_block_1_conv2_b2_conv2d_Conv2D)
    stages_0_block_1_Relu_2 = layers.Activation(name='stages_0_block_1/Relu_2', activation='relu')(stages_0_block_1_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_0_block_1_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_0_block_1/conv3_b2/conv2d/Conv2D', input=stages_0_block_1_Relu_2, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_0_block_1_add = my_add()([stages_0_block_1_conv3_b2_conv2d_Conv2D, stages_0_block_0_add])
    stages_0_block_2_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_0_block_2/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_0_block_1_add)
    stages_0_block_2_Relu = layers.Activation(name='stages_0_block_2/Relu', activation='relu')(stages_0_block_2_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_0_block_2_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_0_block_2/conv1_b2/conv2d/Conv2D', input=stages_0_block_2_Relu, group=1, conv_type='layers.Conv2D', filters=64, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_0_block_2_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_0_block_2/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_0_block_2_conv1_b2_conv2d_Conv2D)
    stages_0_block_2_Relu_1 = layers.Activation(name='stages_0_block_2/Relu_1', activation='relu')(stages_0_block_2_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_0_block_2_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_0_block_2/conv2_b2/conv2d/Conv2D', input=stages_0_block_2_Relu_1, group=1, conv_type='layers.Conv2D', filters=64, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_0_block_2_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_0_block_2/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_0_block_2_conv2_b2_conv2d_Conv2D)
    stages_0_block_2_Relu_2 = layers.Activation(name='stages_0_block_2/Relu_2', activation='relu')(stages_0_block_2_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_0_block_2_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_0_block_2/conv3_b2/conv2d/Conv2D', input=stages_0_block_2_Relu_2, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_0_block_2_add = my_add()([stages_0_block_2_conv3_b2_conv2d_Conv2D, stages_0_block_1_add])
    stages_1_block_0_conv1_b1_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_1_block_0/conv1_b1_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_0_block_2_add)
    stages_1_block_0_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_1_block_0/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_0_block_2_add)
    stages_1_block_0_Relu = layers.Activation(name='stages_1_block_0/Relu', activation='relu')(stages_1_block_0_conv1_b1_bn_batch_normalization_FusedBatchNorm)
    stages_1_block_0_Relu_1 = layers.Activation(name='stages_1_block_0/Relu_1', activation='relu')(stages_1_block_0_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_1_block_0_Pad = layers.ZeroPadding2D(name='stages_1_block_0/Pad', padding=((0, 0), (0, 0)))(stages_1_block_0_Relu)
    stages_1_block_0_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_1_block_0/conv1_b2/conv2d/Conv2D', input=stages_1_block_0_Relu_1, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_1_block_0_conv1_b1_conv2d_Conv2D = convolution(weights_dict, name='stages_1_block_0/conv1_b1/conv2d/Conv2D', input=stages_1_block_0_Pad, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(1, 1), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=None)
    stages_1_block_0_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_1_block_0/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_1_block_0_conv1_b2_conv2d_Conv2D)
    stages_1_block_0_Relu_2 = layers.Activation(name='stages_1_block_0/Relu_2', activation='relu')(stages_1_block_0_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_1_block_0_Pad_1 = layers.ZeroPadding2D(name='stages_1_block_0/Pad_1', padding=((1, 1), (1, 1)))(stages_1_block_0_Relu_2)
    stages_1_block_0_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_1_block_0/conv2_b2/conv2d/Conv2D', input=stages_1_block_0_Pad_1, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(3, 3), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=None)
    stages_1_block_0_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_1_block_0/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_1_block_0_conv2_b2_conv2d_Conv2D)
    stages_1_block_0_Relu_3 = layers.Activation(name='stages_1_block_0/Relu_3', activation='relu')(stages_1_block_0_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_1_block_0_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_1_block_0/conv3_b2/conv2d/Conv2D', input=stages_1_block_0_Relu_3, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_1_block_0_add = my_add()([stages_1_block_0_conv3_b2_conv2d_Conv2D, stages_1_block_0_conv1_b1_conv2d_Conv2D])
    stages_1_block_1_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_1_block_1/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_1_block_0_add)
    stages_1_block_1_Relu = layers.Activation(name='stages_1_block_1/Relu', activation='relu')(stages_1_block_1_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_1_block_1_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_1_block_1/conv1_b2/conv2d/Conv2D', input=stages_1_block_1_Relu, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_1_block_1_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_1_block_1/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_1_block_1_conv1_b2_conv2d_Conv2D)
    stages_1_block_1_Relu_1 = layers.Activation(name='stages_1_block_1/Relu_1', activation='relu')(stages_1_block_1_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_1_block_1_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_1_block_1/conv2_b2/conv2d/Conv2D', input=stages_1_block_1_Relu_1, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_1_block_1_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_1_block_1/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_1_block_1_conv2_b2_conv2d_Conv2D)
    stages_1_block_1_Relu_2 = layers.Activation(name='stages_1_block_1/Relu_2', activation='relu')(stages_1_block_1_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_1_block_1_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_1_block_1/conv3_b2/conv2d/Conv2D', input=stages_1_block_1_Relu_2, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_1_block_1_add = my_add()([stages_1_block_1_conv3_b2_conv2d_Conv2D, stages_1_block_0_add])
    stages_1_block_2_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_1_block_2/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_1_block_1_add)
    stages_1_block_2_Relu = layers.Activation(name='stages_1_block_2/Relu', activation='relu')(stages_1_block_2_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_1_block_2_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_1_block_2/conv1_b2/conv2d/Conv2D', input=stages_1_block_2_Relu, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_1_block_2_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_1_block_2/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_1_block_2_conv1_b2_conv2d_Conv2D)
    stages_1_block_2_Relu_1 = layers.Activation(name='stages_1_block_2/Relu_1', activation='relu')(stages_1_block_2_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_1_block_2_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_1_block_2/conv2_b2/conv2d/Conv2D', input=stages_1_block_2_Relu_1, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_1_block_2_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_1_block_2/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_1_block_2_conv2_b2_conv2d_Conv2D)
    stages_1_block_2_Relu_2 = layers.Activation(name='stages_1_block_2/Relu_2', activation='relu')(stages_1_block_2_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_1_block_2_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_1_block_2/conv3_b2/conv2d/Conv2D', input=stages_1_block_2_Relu_2, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_1_block_2_add = my_add()([stages_1_block_2_conv3_b2_conv2d_Conv2D, stages_1_block_1_add])
    stages_1_block_3_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_1_block_3/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_1_block_2_add)
    stages_1_block_3_Relu = layers.Activation(name='stages_1_block_3/Relu', activation='relu')(stages_1_block_3_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_1_block_3_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_1_block_3/conv1_b2/conv2d/Conv2D', input=stages_1_block_3_Relu, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_1_block_3_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_1_block_3/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_1_block_3_conv1_b2_conv2d_Conv2D)
    stages_1_block_3_Relu_1 = layers.Activation(name='stages_1_block_3/Relu_1', activation='relu')(stages_1_block_3_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_1_block_3_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_1_block_3/conv2_b2/conv2d/Conv2D', input=stages_1_block_3_Relu_1, group=1, conv_type='layers.Conv2D', filters=128, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_1_block_3_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_1_block_3/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_1_block_3_conv2_b2_conv2d_Conv2D)
    stages_1_block_3_Relu_2 = layers.Activation(name='stages_1_block_3/Relu_2', activation='relu')(stages_1_block_3_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_1_block_3_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_1_block_3/conv3_b2/conv2d/Conv2D', input=stages_1_block_3_Relu_2, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_1_block_3_add = my_add()([stages_1_block_3_conv3_b2_conv2d_Conv2D, stages_1_block_2_add])
    stages_2_block_0_conv1_b1_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_0/conv1_b1_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_1_block_3_add)
    stages_2_block_0_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_0/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_1_block_3_add)
    stages_2_block_0_Relu = layers.Activation(name='stages_2_block_0/Relu', activation='relu')(stages_2_block_0_conv1_b1_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_0_Relu_1 = layers.Activation(name='stages_2_block_0/Relu_1', activation='relu')(stages_2_block_0_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_0_Pad = layers.ZeroPadding2D(name='stages_2_block_0/Pad', padding=((0, 0), (0, 0)))(stages_2_block_0_Relu)
    stages_2_block_0_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_0/conv1_b2/conv2d/Conv2D', input=stages_2_block_0_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_0_conv1_b1_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_0/conv1_b1/conv2d/Conv2D', input=stages_2_block_0_Pad, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=None)
    stages_2_block_0_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_0/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_0_conv1_b2_conv2d_Conv2D)
    stages_2_block_0_Relu_2 = layers.Activation(name='stages_2_block_0/Relu_2', activation='relu')(stages_2_block_0_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_0_Pad_1 = layers.ZeroPadding2D(name='stages_2_block_0/Pad_1', padding=((1, 1), (1, 1)))(stages_2_block_0_Relu_2)
    stages_2_block_0_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_0/conv2_b2/conv2d/Conv2D', input=stages_2_block_0_Pad_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=None)
    stages_2_block_0_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_0/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_0_conv2_b2_conv2d_Conv2D)
    stages_2_block_0_Relu_3 = layers.Activation(name='stages_2_block_0/Relu_3', activation='relu')(stages_2_block_0_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_0_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_0/conv3_b2/conv2d/Conv2D', input=stages_2_block_0_Relu_3, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_0_add = my_add()([stages_2_block_0_conv3_b2_conv2d_Conv2D, stages_2_block_0_conv1_b1_conv2d_Conv2D])
    stages_2_block_1_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_1/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_0_add)
    stages_2_block_1_Relu = layers.Activation(name='stages_2_block_1/Relu', activation='relu')(stages_2_block_1_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_1_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_1/conv1_b2/conv2d/Conv2D', input=stages_2_block_1_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_1_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_1/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_1_conv1_b2_conv2d_Conv2D)
    stages_2_block_1_Relu_1 = layers.Activation(name='stages_2_block_1/Relu_1', activation='relu')(stages_2_block_1_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_1_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_1/conv2_b2/conv2d/Conv2D', input=stages_2_block_1_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_1_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_1/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_1_conv2_b2_conv2d_Conv2D)
    stages_2_block_1_Relu_2 = layers.Activation(name='stages_2_block_1/Relu_2', activation='relu')(stages_2_block_1_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_1_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_1/conv3_b2/conv2d/Conv2D', input=stages_2_block_1_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_1_add = my_add()([stages_2_block_1_conv3_b2_conv2d_Conv2D, stages_2_block_0_add])
    stages_2_block_2_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_2/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_1_add)
    stages_2_block_2_Relu = layers.Activation(name='stages_2_block_2/Relu', activation='relu')(stages_2_block_2_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_2_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_2/conv1_b2/conv2d/Conv2D', input=stages_2_block_2_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_2_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_2/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_2_conv1_b2_conv2d_Conv2D)
    stages_2_block_2_Relu_1 = layers.Activation(name='stages_2_block_2/Relu_1', activation='relu')(stages_2_block_2_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_2_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_2/conv2_b2/conv2d/Conv2D', input=stages_2_block_2_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_2_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_2/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_2_conv2_b2_conv2d_Conv2D)
    stages_2_block_2_Relu_2 = layers.Activation(name='stages_2_block_2/Relu_2', activation='relu')(stages_2_block_2_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_2_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_2/conv3_b2/conv2d/Conv2D', input=stages_2_block_2_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_2_add = my_add()([stages_2_block_2_conv3_b2_conv2d_Conv2D, stages_2_block_1_add])
    stages_2_block_3_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_3/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_2_add)
    stages_2_block_3_Relu = layers.Activation(name='stages_2_block_3/Relu', activation='relu')(stages_2_block_3_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_3_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_3/conv1_b2/conv2d/Conv2D', input=stages_2_block_3_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_3_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_3/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_3_conv1_b2_conv2d_Conv2D)
    stages_2_block_3_Relu_1 = layers.Activation(name='stages_2_block_3/Relu_1', activation='relu')(stages_2_block_3_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_3_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_3/conv2_b2/conv2d/Conv2D', input=stages_2_block_3_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_3_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_3/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_3_conv2_b2_conv2d_Conv2D)
    stages_2_block_3_Relu_2 = layers.Activation(name='stages_2_block_3/Relu_2', activation='relu')(stages_2_block_3_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_3_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_3/conv3_b2/conv2d/Conv2D', input=stages_2_block_3_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_3_add = my_add()([stages_2_block_3_conv3_b2_conv2d_Conv2D, stages_2_block_2_add])
    stages_2_block_4_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_4/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_3_add)
    stages_2_block_4_Relu = layers.Activation(name='stages_2_block_4/Relu', activation='relu')(stages_2_block_4_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_4_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_4/conv1_b2/conv2d/Conv2D', input=stages_2_block_4_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_4_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_4/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_4_conv1_b2_conv2d_Conv2D)
    stages_2_block_4_Relu_1 = layers.Activation(name='stages_2_block_4/Relu_1', activation='relu')(stages_2_block_4_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_4_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_4/conv2_b2/conv2d/Conv2D', input=stages_2_block_4_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_4_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_4/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_4_conv2_b2_conv2d_Conv2D)
    stages_2_block_4_Relu_2 = layers.Activation(name='stages_2_block_4/Relu_2', activation='relu')(stages_2_block_4_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_4_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_4/conv3_b2/conv2d/Conv2D', input=stages_2_block_4_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_4_add = my_add()([stages_2_block_4_conv3_b2_conv2d_Conv2D, stages_2_block_3_add])
    stages_2_block_5_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_5/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_4_add)
    stages_2_block_5_Relu = layers.Activation(name='stages_2_block_5/Relu', activation='relu')(stages_2_block_5_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_5_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_5/conv1_b2/conv2d/Conv2D', input=stages_2_block_5_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_5_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_5/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_5_conv1_b2_conv2d_Conv2D)
    stages_2_block_5_Relu_1 = layers.Activation(name='stages_2_block_5/Relu_1', activation='relu')(stages_2_block_5_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_5_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_5/conv2_b2/conv2d/Conv2D', input=stages_2_block_5_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_5_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_5/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_5_conv2_b2_conv2d_Conv2D)
    stages_2_block_5_Relu_2 = layers.Activation(name='stages_2_block_5/Relu_2', activation='relu')(stages_2_block_5_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_5_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_5/conv3_b2/conv2d/Conv2D', input=stages_2_block_5_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_5_add = my_add()([stages_2_block_5_conv3_b2_conv2d_Conv2D, stages_2_block_4_add])
    stages_2_block_6_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_6/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_5_add)
    stages_2_block_6_Relu = layers.Activation(name='stages_2_block_6/Relu', activation='relu')(stages_2_block_6_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_6_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_6/conv1_b2/conv2d/Conv2D', input=stages_2_block_6_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_6_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_6/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_6_conv1_b2_conv2d_Conv2D)
    stages_2_block_6_Relu_1 = layers.Activation(name='stages_2_block_6/Relu_1', activation='relu')(stages_2_block_6_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_6_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_6/conv2_b2/conv2d/Conv2D', input=stages_2_block_6_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_6_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_6/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_6_conv2_b2_conv2d_Conv2D)
    stages_2_block_6_Relu_2 = layers.Activation(name='stages_2_block_6/Relu_2', activation='relu')(stages_2_block_6_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_6_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_6/conv3_b2/conv2d/Conv2D', input=stages_2_block_6_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_6_add = my_add()([stages_2_block_6_conv3_b2_conv2d_Conv2D, stages_2_block_5_add])
    stages_2_block_7_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_7/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_6_add)
    stages_2_block_7_Relu = layers.Activation(name='stages_2_block_7/Relu', activation='relu')(stages_2_block_7_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_7_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_7/conv1_b2/conv2d/Conv2D', input=stages_2_block_7_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_7_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_7/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_7_conv1_b2_conv2d_Conv2D)
    stages_2_block_7_Relu_1 = layers.Activation(name='stages_2_block_7/Relu_1', activation='relu')(stages_2_block_7_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_7_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_7/conv2_b2/conv2d/Conv2D', input=stages_2_block_7_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_7_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_7/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_7_conv2_b2_conv2d_Conv2D)
    stages_2_block_7_Relu_2 = layers.Activation(name='stages_2_block_7/Relu_2', activation='relu')(stages_2_block_7_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_7_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_7/conv3_b2/conv2d/Conv2D', input=stages_2_block_7_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_7_add = my_add()([stages_2_block_7_conv3_b2_conv2d_Conv2D, stages_2_block_6_add])
    stages_2_block_8_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_8/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_7_add)
    stages_2_block_8_Relu = layers.Activation(name='stages_2_block_8/Relu', activation='relu')(stages_2_block_8_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_8_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_8/conv1_b2/conv2d/Conv2D', input=stages_2_block_8_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_8_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_8/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_8_conv1_b2_conv2d_Conv2D)
    stages_2_block_8_Relu_1 = layers.Activation(name='stages_2_block_8/Relu_1', activation='relu')(stages_2_block_8_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_8_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_8/conv2_b2/conv2d/Conv2D', input=stages_2_block_8_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_8_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_8/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_8_conv2_b2_conv2d_Conv2D)
    stages_2_block_8_Relu_2 = layers.Activation(name='stages_2_block_8/Relu_2', activation='relu')(stages_2_block_8_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_8_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_8/conv3_b2/conv2d/Conv2D', input=stages_2_block_8_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_8_add = my_add()([stages_2_block_8_conv3_b2_conv2d_Conv2D, stages_2_block_7_add])
    stages_2_block_9_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_9/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_8_add)
    stages_2_block_9_Relu = layers.Activation(name='stages_2_block_9/Relu', activation='relu')(stages_2_block_9_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_9_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_9/conv1_b2/conv2d/Conv2D', input=stages_2_block_9_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_9_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_9/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_9_conv1_b2_conv2d_Conv2D)
    stages_2_block_9_Relu_1 = layers.Activation(name='stages_2_block_9/Relu_1', activation='relu')(stages_2_block_9_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_9_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_9/conv2_b2/conv2d/Conv2D', input=stages_2_block_9_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_9_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_9/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_9_conv2_b2_conv2d_Conv2D)
    stages_2_block_9_Relu_2 = layers.Activation(name='stages_2_block_9/Relu_2', activation='relu')(stages_2_block_9_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_9_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_9/conv3_b2/conv2d/Conv2D', input=stages_2_block_9_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_9_add = my_add()([stages_2_block_9_conv3_b2_conv2d_Conv2D, stages_2_block_8_add])
    stages_2_block_10_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_10/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_9_add)
    stages_2_block_10_Relu = layers.Activation(name='stages_2_block_10/Relu', activation='relu')(stages_2_block_10_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_10_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_10/conv1_b2/conv2d/Conv2D', input=stages_2_block_10_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_10_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_10/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_10_conv1_b2_conv2d_Conv2D)
    stages_2_block_10_Relu_1 = layers.Activation(name='stages_2_block_10/Relu_1', activation='relu')(stages_2_block_10_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_10_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_10/conv2_b2/conv2d/Conv2D', input=stages_2_block_10_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_10_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_10/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_10_conv2_b2_conv2d_Conv2D)
    stages_2_block_10_Relu_2 = layers.Activation(name='stages_2_block_10/Relu_2', activation='relu')(stages_2_block_10_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_10_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_10/conv3_b2/conv2d/Conv2D', input=stages_2_block_10_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_10_add = my_add()([stages_2_block_10_conv3_b2_conv2d_Conv2D, stages_2_block_9_add])
    stages_2_block_11_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_11/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_10_add)
    stages_2_block_11_Relu = layers.Activation(name='stages_2_block_11/Relu', activation='relu')(stages_2_block_11_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_11_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_11/conv1_b2/conv2d/Conv2D', input=stages_2_block_11_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_11_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_11/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_11_conv1_b2_conv2d_Conv2D)
    stages_2_block_11_Relu_1 = layers.Activation(name='stages_2_block_11/Relu_1', activation='relu')(stages_2_block_11_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_11_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_11/conv2_b2/conv2d/Conv2D', input=stages_2_block_11_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_11_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_11/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_11_conv2_b2_conv2d_Conv2D)
    stages_2_block_11_Relu_2 = layers.Activation(name='stages_2_block_11/Relu_2', activation='relu')(stages_2_block_11_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_11_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_11/conv3_b2/conv2d/Conv2D', input=stages_2_block_11_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_11_add = my_add()([stages_2_block_11_conv3_b2_conv2d_Conv2D, stages_2_block_10_add])
    stages_2_block_12_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_12/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_11_add)
    stages_2_block_12_Relu = layers.Activation(name='stages_2_block_12/Relu', activation='relu')(stages_2_block_12_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_12_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_12/conv1_b2/conv2d/Conv2D', input=stages_2_block_12_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_12_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_12/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_12_conv1_b2_conv2d_Conv2D)
    stages_2_block_12_Relu_1 = layers.Activation(name='stages_2_block_12/Relu_1', activation='relu')(stages_2_block_12_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_12_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_12/conv2_b2/conv2d/Conv2D', input=stages_2_block_12_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_12_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_12/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_12_conv2_b2_conv2d_Conv2D)
    stages_2_block_12_Relu_2 = layers.Activation(name='stages_2_block_12/Relu_2', activation='relu')(stages_2_block_12_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_12_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_12/conv3_b2/conv2d/Conv2D', input=stages_2_block_12_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_12_add = my_add()([stages_2_block_12_conv3_b2_conv2d_Conv2D, stages_2_block_11_add])
    stages_2_block_13_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_13/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_12_add)
    stages_2_block_13_Relu = layers.Activation(name='stages_2_block_13/Relu', activation='relu')(stages_2_block_13_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_13_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_13/conv1_b2/conv2d/Conv2D', input=stages_2_block_13_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_13_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_13/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_13_conv1_b2_conv2d_Conv2D)
    stages_2_block_13_Relu_1 = layers.Activation(name='stages_2_block_13/Relu_1', activation='relu')(stages_2_block_13_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_13_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_13/conv2_b2/conv2d/Conv2D', input=stages_2_block_13_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_13_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_13/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_13_conv2_b2_conv2d_Conv2D)
    stages_2_block_13_Relu_2 = layers.Activation(name='stages_2_block_13/Relu_2', activation='relu')(stages_2_block_13_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_13_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_13/conv3_b2/conv2d/Conv2D', input=stages_2_block_13_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_13_add = my_add()([stages_2_block_13_conv3_b2_conv2d_Conv2D, stages_2_block_12_add])
    stages_2_block_14_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_14/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_13_add)
    stages_2_block_14_Relu = layers.Activation(name='stages_2_block_14/Relu', activation='relu')(stages_2_block_14_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_14_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_14/conv1_b2/conv2d/Conv2D', input=stages_2_block_14_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_14_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_14/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_14_conv1_b2_conv2d_Conv2D)
    stages_2_block_14_Relu_1 = layers.Activation(name='stages_2_block_14/Relu_1', activation='relu')(stages_2_block_14_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_14_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_14/conv2_b2/conv2d/Conv2D', input=stages_2_block_14_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_14_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_14/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_14_conv2_b2_conv2d_Conv2D)
    stages_2_block_14_Relu_2 = layers.Activation(name='stages_2_block_14/Relu_2', activation='relu')(stages_2_block_14_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_14_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_14/conv3_b2/conv2d/Conv2D', input=stages_2_block_14_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_14_add = my_add()([stages_2_block_14_conv3_b2_conv2d_Conv2D, stages_2_block_13_add])
    stages_2_block_15_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_15/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_14_add)
    stages_2_block_15_Relu = layers.Activation(name='stages_2_block_15/Relu', activation='relu')(stages_2_block_15_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_15_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_15/conv1_b2/conv2d/Conv2D', input=stages_2_block_15_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_15_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_15/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_15_conv1_b2_conv2d_Conv2D)
    stages_2_block_15_Relu_1 = layers.Activation(name='stages_2_block_15/Relu_1', activation='relu')(stages_2_block_15_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_15_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_15/conv2_b2/conv2d/Conv2D', input=stages_2_block_15_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_15_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_15/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_15_conv2_b2_conv2d_Conv2D)
    stages_2_block_15_Relu_2 = layers.Activation(name='stages_2_block_15/Relu_2', activation='relu')(stages_2_block_15_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_15_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_15/conv3_b2/conv2d/Conv2D', input=stages_2_block_15_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_15_add = my_add()([stages_2_block_15_conv3_b2_conv2d_Conv2D, stages_2_block_14_add])
    stages_2_block_16_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_16/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_15_add)
    stages_2_block_16_Relu = layers.Activation(name='stages_2_block_16/Relu', activation='relu')(stages_2_block_16_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_16_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_16/conv1_b2/conv2d/Conv2D', input=stages_2_block_16_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_16_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_16/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_16_conv1_b2_conv2d_Conv2D)
    stages_2_block_16_Relu_1 = layers.Activation(name='stages_2_block_16/Relu_1', activation='relu')(stages_2_block_16_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_16_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_16/conv2_b2/conv2d/Conv2D', input=stages_2_block_16_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_16_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_16/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_16_conv2_b2_conv2d_Conv2D)
    stages_2_block_16_Relu_2 = layers.Activation(name='stages_2_block_16/Relu_2', activation='relu')(stages_2_block_16_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_16_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_16/conv3_b2/conv2d/Conv2D', input=stages_2_block_16_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_16_add = my_add()([stages_2_block_16_conv3_b2_conv2d_Conv2D, stages_2_block_15_add])
    stages_2_block_17_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_17/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_16_add)
    stages_2_block_17_Relu = layers.Activation(name='stages_2_block_17/Relu', activation='relu')(stages_2_block_17_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_17_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_17/conv1_b2/conv2d/Conv2D', input=stages_2_block_17_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_17_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_17/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_17_conv1_b2_conv2d_Conv2D)
    stages_2_block_17_Relu_1 = layers.Activation(name='stages_2_block_17/Relu_1', activation='relu')(stages_2_block_17_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_17_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_17/conv2_b2/conv2d/Conv2D', input=stages_2_block_17_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_17_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_17/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_17_conv2_b2_conv2d_Conv2D)
    stages_2_block_17_Relu_2 = layers.Activation(name='stages_2_block_17/Relu_2', activation='relu')(stages_2_block_17_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_17_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_17/conv3_b2/conv2d/Conv2D', input=stages_2_block_17_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_17_add = my_add()([stages_2_block_17_conv3_b2_conv2d_Conv2D, stages_2_block_16_add])
    stages_2_block_18_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_18/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_17_add)
    stages_2_block_18_Relu = layers.Activation(name='stages_2_block_18/Relu', activation='relu')(stages_2_block_18_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_18_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_18/conv1_b2/conv2d/Conv2D', input=stages_2_block_18_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_18_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_18/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_18_conv1_b2_conv2d_Conv2D)
    stages_2_block_18_Relu_1 = layers.Activation(name='stages_2_block_18/Relu_1', activation='relu')(stages_2_block_18_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_18_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_18/conv2_b2/conv2d/Conv2D', input=stages_2_block_18_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_18_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_18/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_18_conv2_b2_conv2d_Conv2D)
    stages_2_block_18_Relu_2 = layers.Activation(name='stages_2_block_18/Relu_2', activation='relu')(stages_2_block_18_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_18_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_18/conv3_b2/conv2d/Conv2D', input=stages_2_block_18_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_18_add = my_add()([stages_2_block_18_conv3_b2_conv2d_Conv2D, stages_2_block_17_add])
    stages_2_block_19_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_19/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_18_add)
    stages_2_block_19_Relu = layers.Activation(name='stages_2_block_19/Relu', activation='relu')(stages_2_block_19_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_19_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_19/conv1_b2/conv2d/Conv2D', input=stages_2_block_19_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_19_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_19/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_19_conv1_b2_conv2d_Conv2D)
    stages_2_block_19_Relu_1 = layers.Activation(name='stages_2_block_19/Relu_1', activation='relu')(stages_2_block_19_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_19_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_19/conv2_b2/conv2d/Conv2D', input=stages_2_block_19_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_19_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_19/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_19_conv2_b2_conv2d_Conv2D)
    stages_2_block_19_Relu_2 = layers.Activation(name='stages_2_block_19/Relu_2', activation='relu')(stages_2_block_19_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_19_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_19/conv3_b2/conv2d/Conv2D', input=stages_2_block_19_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_19_add = my_add()([stages_2_block_19_conv3_b2_conv2d_Conv2D, stages_2_block_18_add])
    stages_2_block_20_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_20/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_19_add)
    stages_2_block_20_Relu = layers.Activation(name='stages_2_block_20/Relu', activation='relu')(stages_2_block_20_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_20_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_20/conv1_b2/conv2d/Conv2D', input=stages_2_block_20_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_20_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_20/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_20_conv1_b2_conv2d_Conv2D)
    stages_2_block_20_Relu_1 = layers.Activation(name='stages_2_block_20/Relu_1', activation='relu')(stages_2_block_20_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_20_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_20/conv2_b2/conv2d/Conv2D', input=stages_2_block_20_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_20_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_20/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_20_conv2_b2_conv2d_Conv2D)
    stages_2_block_20_Relu_2 = layers.Activation(name='stages_2_block_20/Relu_2', activation='relu')(stages_2_block_20_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_20_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_20/conv3_b2/conv2d/Conv2D', input=stages_2_block_20_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_20_add = my_add()([stages_2_block_20_conv3_b2_conv2d_Conv2D, stages_2_block_19_add])
    stages_2_block_21_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_21/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_20_add)
    stages_2_block_21_Relu = layers.Activation(name='stages_2_block_21/Relu', activation='relu')(stages_2_block_21_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_21_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_21/conv1_b2/conv2d/Conv2D', input=stages_2_block_21_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_21_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_21/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_21_conv1_b2_conv2d_Conv2D)
    stages_2_block_21_Relu_1 = layers.Activation(name='stages_2_block_21/Relu_1', activation='relu')(stages_2_block_21_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_21_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_21/conv2_b2/conv2d/Conv2D', input=stages_2_block_21_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_21_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_21/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_21_conv2_b2_conv2d_Conv2D)
    stages_2_block_21_Relu_2 = layers.Activation(name='stages_2_block_21/Relu_2', activation='relu')(stages_2_block_21_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_21_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_21/conv3_b2/conv2d/Conv2D', input=stages_2_block_21_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_21_add = my_add()([stages_2_block_21_conv3_b2_conv2d_Conv2D, stages_2_block_20_add])
    stages_2_block_22_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_22/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_21_add)
    stages_2_block_22_Relu = layers.Activation(name='stages_2_block_22/Relu', activation='relu')(stages_2_block_22_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_22_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_22/conv1_b2/conv2d/Conv2D', input=stages_2_block_22_Relu, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_22_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_22/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_22_conv1_b2_conv2d_Conv2D)
    stages_2_block_22_Relu_1 = layers.Activation(name='stages_2_block_22/Relu_1', activation='relu')(stages_2_block_22_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_22_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_22/conv2_b2/conv2d/Conv2D', input=stages_2_block_22_Relu_1, group=1, conv_type='layers.Conv2D', filters=256, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_22_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_2_block_22/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_22_conv2_b2_conv2d_Conv2D)
    stages_2_block_22_Relu_2 = layers.Activation(name='stages_2_block_22/Relu_2', activation='relu')(stages_2_block_22_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_2_block_22_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_2_block_22/conv3_b2/conv2d/Conv2D', input=stages_2_block_22_Relu_2, group=1, conv_type='layers.Conv2D', filters=1024, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_2_block_22_add = my_add()([stages_2_block_22_conv3_b2_conv2d_Conv2D, stages_2_block_21_add])
    stages_3_block_0_conv1_b1_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_3_block_0/conv1_b1_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_22_add)
    stages_3_block_0_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_3_block_0/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_2_block_22_add)
    stages_3_block_0_Relu = layers.Activation(name='stages_3_block_0/Relu', activation='relu')(stages_3_block_0_conv1_b1_bn_batch_normalization_FusedBatchNorm)
    stages_3_block_0_Relu_1 = layers.Activation(name='stages_3_block_0/Relu_1', activation='relu')(stages_3_block_0_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_3_block_0_Pad = layers.ZeroPadding2D(name='stages_3_block_0/Pad', padding=((0, 0), (0, 0)))(stages_3_block_0_Relu)
    stages_3_block_0_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_3_block_0/conv1_b2/conv2d/Conv2D', input=stages_3_block_0_Relu_1, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_3_block_0_conv1_b1_conv2d_Conv2D = convolution(weights_dict, name='stages_3_block_0/conv1_b1/conv2d/Conv2D', input=stages_3_block_0_Pad, group=1, conv_type='layers.Conv2D', filters=2048, kernel_size=(1, 1), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=None)
    stages_3_block_0_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_3_block_0/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_3_block_0_conv1_b2_conv2d_Conv2D)
    stages_3_block_0_Relu_2 = layers.Activation(name='stages_3_block_0/Relu_2', activation='relu')(stages_3_block_0_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_3_block_0_Pad_1 = layers.ZeroPadding2D(name='stages_3_block_0/Pad_1', padding=((1, 1), (1, 1)))(stages_3_block_0_Relu_2)
    stages_3_block_0_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_3_block_0/conv2_b2/conv2d/Conv2D', input=stages_3_block_0_Pad_1, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(3, 3), strides=(2, 2), dilation_rate=(1, 1), padding='valid', use_bias=None)
    stages_3_block_0_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_3_block_0/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_3_block_0_conv2_b2_conv2d_Conv2D)
    stages_3_block_0_Relu_3 = layers.Activation(name='stages_3_block_0/Relu_3', activation='relu')(stages_3_block_0_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_3_block_0_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_3_block_0/conv3_b2/conv2d/Conv2D', input=stages_3_block_0_Relu_3, group=1, conv_type='layers.Conv2D', filters=2048, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_3_block_0_add = my_add()([stages_3_block_0_conv3_b2_conv2d_Conv2D, stages_3_block_0_conv1_b1_conv2d_Conv2D])
    stages_3_block_1_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_3_block_1/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_3_block_0_add)
    stages_3_block_1_Relu = layers.Activation(name='stages_3_block_1/Relu', activation='relu')(stages_3_block_1_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_3_block_1_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_3_block_1/conv1_b2/conv2d/Conv2D', input=stages_3_block_1_Relu, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_3_block_1_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_3_block_1/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_3_block_1_conv1_b2_conv2d_Conv2D)
    stages_3_block_1_Relu_1 = layers.Activation(name='stages_3_block_1/Relu_1', activation='relu')(stages_3_block_1_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_3_block_1_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_3_block_1/conv2_b2/conv2d/Conv2D', input=stages_3_block_1_Relu_1, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_3_block_1_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_3_block_1/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_3_block_1_conv2_b2_conv2d_Conv2D)
    stages_3_block_1_Relu_2 = layers.Activation(name='stages_3_block_1/Relu_2', activation='relu')(stages_3_block_1_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_3_block_1_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_3_block_1/conv3_b2/conv2d/Conv2D', input=stages_3_block_1_Relu_2, group=1, conv_type='layers.Conv2D', filters=2048, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_3_block_1_add = my_add()([stages_3_block_1_conv3_b2_conv2d_Conv2D, stages_3_block_0_add])
    stages_3_block_2_conv1_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_3_block_2/conv1_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_3_block_1_add)
    stages_3_block_2_Relu = layers.Activation(name='stages_3_block_2/Relu', activation='relu')(stages_3_block_2_conv1_b2_bn_batch_normalization_FusedBatchNorm)
    stages_3_block_2_conv1_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_3_block_2/conv1_b2/conv2d/Conv2D', input=stages_3_block_2_Relu, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_3_block_2_conv2_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_3_block_2/conv2_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_3_block_2_conv1_b2_conv2d_Conv2D)
    stages_3_block_2_Relu_1 = layers.Activation(name='stages_3_block_2/Relu_1', activation='relu')(stages_3_block_2_conv2_b2_bn_batch_normalization_FusedBatchNorm)
    stages_3_block_2_conv2_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_3_block_2/conv2_b2/conv2d/Conv2D', input=stages_3_block_2_Relu_1, group=1, conv_type='layers.Conv2D', filters=512, kernel_size=(3, 3), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_3_block_2_conv3_b2_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'stages_3_block_2/conv3_b2_bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_3_block_2_conv2_b2_conv2d_Conv2D)
    stages_3_block_2_Relu_2 = layers.Activation(name='stages_3_block_2/Relu_2', activation='relu')(stages_3_block_2_conv3_b2_bn_batch_normalization_FusedBatchNorm)
    stages_3_block_2_conv3_b2_conv2d_Conv2D = convolution(weights_dict, name='stages_3_block_2/conv3_b2/conv2d/Conv2D', input=stages_3_block_2_Relu_2, group=1, conv_type='layers.Conv2D', filters=2048, kernel_size=(1, 1), strides=(1, 1), dilation_rate=(1, 1), padding='same', use_bias=None)
    stages_3_block_2_add = my_add()([stages_3_block_2_conv3_b2_conv2d_Conv2D, stages_3_block_1_add])
    global_pool_bn_batch_normalization_FusedBatchNorm = layers.BatchNormalization(name = 'global_pool/bn/batch_normalization/FusedBatchNorm', axis = -1, epsilon = 1.0009999641624745e-05, center = True, scale = True)(stages_3_block_2_add)
    global_pool_Relu = layers.Activation(name='global_pool/Relu', activation='relu')(global_pool_bn_batch_normalization_FusedBatchNorm)
    global_pool_Mean = layers.Lambda(lambda x: K.mean(x, axis=[1, 2], keepdims=True))(global_pool_Relu)
    model           = Model(inputs = [transpose], outputs = [global_pool_Mean])
    print(global_pool_Mean.shape)
    set_layer_weights(model, weights_dict)
    return model

def convolution(weights_dict, name, input, group, conv_type, filters=None, **kwargs):
    if not conv_type.startswith('layer'):
        layer = keras.applications.mobilenet.DepthwiseConv2D(name=name, **kwargs)(input)
        return layer
    elif conv_type == 'layers.DepthwiseConv2D':
        layer = layers.DepthwiseConv2D(name=name, **kwargs)(input)
        return layer
    
    inp_filters = K.int_shape(input)[-1]
    inp_grouped_channels = int(inp_filters / group)
    out_grouped_channels = int(filters / group)
    group_list = []
    if group == 1:
        func = getattr(layers, conv_type.split('.')[-1])
        layer = func(name = name, filters = filters, **kwargs)(input)
        return layer
    weight_groups = list()
    if not weights_dict == None:
        w = np.array(weights_dict[name]['weights'])
        weight_groups = np.split(w, indices_or_sections=group, axis=-1)
    for c in range(group):
        x = layers.Lambda(lambda z: z[..., c * inp_grouped_channels:(c + 1) * inp_grouped_channels])(input)
        x = layers.Conv2D(name=name + "_" + str(c), filters=out_grouped_channels, **kwargs)(x)
        weights_dict[name + "_" + str(c)] = dict()
        weights_dict[name + "_" + str(c)]['weights'] = weight_groups[c]
        group_list.append(x)
    layer = layers.concatenate(group_list, axis = -1)
    if 'bias' in weights_dict[name]:
        b = K.variable(weights_dict[name]['bias'], name = name + "_bias")
        layer = layer + b
    return layer

class my_add(keras.layers.Layer):
    def __init__(self, **kwargs):
        super(my_add, self).__init__(**kwargs)
    def call(self, inputs):
        res = inputs[0] + inputs[1]
        self.output_shapes = K.int_shape(res)
        return res
    
    def compute_output_shape(self, input_shape):
        return self.output_shapes


import argparse
if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('-i', dest='input', help="input npy", required=True)
    parser.add_argument('-o', dest='output', help="output h5", default='model.h5')
    args = parser.parse_args()
    weight_filepath = args.input
    dump_filepath = args.output
    model = KitModel(weight_filepath)
    model.save(dump_filepath)